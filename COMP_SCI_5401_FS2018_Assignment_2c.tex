\documentclass[11pt]{article}
\usepackage[left=3cm, right=3cm, top=2cm]{geometry}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{float}
\usepackage{enumitem}

% Prevent heading numbers
\setcounter{secnumdepth}{0}

% Command definitions 
\newcommand{\fitnessplotcaption}[2]{\caption{Global Best Fitness versus Fitness Evaluations for the \textbf{{#1}}, Randomly Generated Worlds. The figure was generated with data obtained by running the GP with the \textbf{{#2}} configuration file.}}

\newcommand{\addgraphic}[1]{\centerline{\includegraphics[scale=0.7]{output/#1_graph.png}}}

\newcommand{\tablecaption}[1]{\caption{Statistical Analysis performed on {#1}}}

\title{COMP SCI 5401 FS2018 Assignment 2c}
\author{William  Lorey \\ wwlytc@mst.edu}
\date{}

\begin{document}

\maketitle

\tableofcontents

\section{Methodology}
For assignment 2c, an Evolutionary Algorithm (EA) employing Genetic Programming (GP) alongside a 
Coevolutionary Search was used to coevolve controllers to play pacman. 
Controllers for both pacman and the ghosts were evolved in tandem.
In addition to the implementation of standard EA and GP paradigms as outlined as part of the requirements for this assignment, 
the custom parts of this EA include a controller tree mutation strategy, the function and terminal sets, and
mechanics of pairing controllers with other controllers and also with pacman game worlds.

Mutation was probabilistically performed (with a user-configurable probability) on each member of both
controller populations (both for pacman and for the ghosts) following the completion of recombination 
to obtain the child population members.
The mutation itself was a sub-tree mutation. If mutation was determined to act on a population member, 
it functioned by first selecting a random node from the controller tree. Then the sub-tree of the chosen
node was 'nullified`. As the tree was stored as an array maintaining the heap property (each child node 
can be found from the parent index in a predictable way), this functionality was required to set the value of 
each node in the chosen sub-tree to a null value so rouge nodes would not impact the tree's functioning after 
mutation. A 'grow` method was then applied to the chosen node, randomly adding \texttt{n} subsequent levels
to the sub-tree, where the inclusive range of \texttt{n} was user-configurable. In this implementation,
a full tree was grown from the chosen node, ensuring that leaf nodes were part of the terminal set and that
interior nodes were part of the function set. This form of mutation was chosen due to its simplistic 
nature and effectiveness in slightly modifying controllers with (typically) minimal destruction of the 
original controller tree.

In order for a GP tree to produce reasonable, predictable output, node selections from two sets of nodes were
made: the function set of nodes and the terminal set of nodes. As taken from standard GP and backed up by logical reasoning,
the GP tree in this assignment was constructed with function nodes always making up the interior nodes
of the controller trees, and terminal nodes always making up the leaf nodes of the controller trees. The compatibility of nodes
was also important. For ease of constructing and evaluating trees, all function nodes took two inputs of floating point
numbers, and all terminal nodes evaluated to floating point numbers. This
ensured that when trees were interpreted to produce a crisp numerical output, they could be compiled correctly without errors.

The function nodes used for both the pacman and ghost controller trees were standard and provided as part of the assignment: 
addition, subtraction, multiplication, division, and random (choose a random floating point number 
within a given range). The implementation of these operations were straightforward except for division and
random. For division, division by zero was protected for. If a number was to be divided by zero, the result
would become zero. For the random operation, as implemented in python, a random selection made using a call
to the \texttt{random} library required the lower bound to be smaller than the upper bound. This was solved
by always supplying the minimum floating point value as the lower bound and the maximum floating point value
as the upper bound.

Terminal nodes differed for the pacman and ghost controllers. The pacman controllers used the following terminal nodes: 
Manhattan distance between pacman and the nearest ghost, Manhattan distance between pacman and the nearest pill, Manhattan
distance between pacman and the nearest fruit, number of walls adjacent to pacman, a floating point constant, and Manhattan
distance to the nearest other pacman (for the BONUS2* assignments). These nodes were implemented in accordance with the 
main assignment deliverables. One main comment about implementation particulars for the pacman nodes would be that if a fruit
was not placed in the world, the distance to nearest fruit node would evaluate to a user-configurable arbitrary large number.
Similarly for the ghost terminal nodes, which include the Manhattan distance to the nearest pacman, Manhattan distance to
the nearest ghost, and a floating point constant, the majority of nodes were implemented as part of the main assignment deliverables.
The floating point constant was not required for the ghost controller terminal nodes, but it seemed useful to include it, 
as it may provide useful information to the controller while not increasing the search space drastically.

To complete runs of the experiment, pairings of pacman controllers to ghost controllers had to be performed. To facilitate this
process, a data structure was created which included the unit controller class and the fitness of that controller. Once both
populations of controller-fitness objects were generated (either by the initial population generation or through recombination and mutation), the controllers
were randomly paired by taking, for each index in both unordered populations, one controller from each population. To evaluate
the controllers, each pairing was matched with a pacman world with its own generated wall and pill placements. The controllers were applied
to this world by running a game to determine the controller fitnesses. This approach allowed for sufficient abstraction to keep 
the process easy to understand and implement while providing stochastic pairing of controllers and pacman world.


\section{Experimental Setup}
All experiments for this assignment were run using custom configuration files, with each file
testing the algorithm against a slightly different set of parameters. Each configuration that was employed is included
as part of the git repository in the \texttt{config} directory. The experiments themselves were each run on one of the S\&T campus
linux machines, with each employed machine running one EA on a time-shared basis with other users of the machines using them for their own
purposes. 

When employing a custom configuration file in experimentation, the following command (for example) was used:

\vspace{5mm}

{\centering \texttt{./run.sh config/config\_file.cfg}\par }

\vspace{5mm}

Where \texttt{config\_file.cfg} could be replaced with any configuration file in the \texttt{config} directory, or
omitted entirely. In the case where the configuration file is omitted, \texttt{config/default.cfg} would be used 
as the configuration file.

To directly reproduce experiments, a configuration option to use a provided random number seed has been included. In each log
file generated after an experiment run, the seed used as part of that experiment is saved. To use a seed to reproduce
an experiment, modify the following fields like so:

\vspace{5mm}

\texttt{use external seed = True}

\texttt{default seed = \textit{<insert seed value here>}}

\vspace{5mm}

The three varying configurations test as part of this assignment's deliverables were all configured with the following
\textit{shared} parameters:

\begin{itemize}
    \item 30 runs
    \item 2000 fitness evaluations
    \item \( \mu \) pacman = 20
    \item \( \lambda \) pacman = 60
    \item \( \mu \) ghost = 20
    \item \( \lambda \) ghost = 60
    \item comma survival strategy for ghosts and pacmen
    \item single controller single pacman
    \item single controller for three ghosts
\end{itemize}

Other parameters exist that are not mentioned above that were excluded for brevity. These parameters can be 
viewed in the configuration files.

The testable differences between deliverable configurations, for each deliverable, are as follows:

\textbf{Deliverable 1}
\begin{itemize}[leftmargin=.8in]
    \item Parent Selection: Over-Selection
    \item Survival Selection: k-Tournament (k pacman = 5, k ghost = 5)
\end{itemize}

\textbf{Deliverable 2}
\begin{itemize}[leftmargin=.8in]
    \item Parent Selection: Fitness Proportional Selection (FPS)
    \item Survival Selection: k-Tournament (k pacman = 5, k ghost = 5)
\end{itemize}

\textbf{Deliverable 3}
\begin{itemize}[leftmargin=.8in]
    \item Parent Selection: Over-Selection
    \item Survival Selection: Truncation
\end{itemize}

Note that the selection methods chosen were applied to both parent and survival selection for pacman and the ghosts.

Because the number of required configuration comparisons for this assignment was relatively small, parent and
survival selections were chosen to be compared. They provide a coarse-grained exploration that can be
performed with a minimal number of comparisons, and their impact on EA performance is of consequence. More fine-tuneable
parameters could be explored, such as the parsimony coefficient of \texttt{k} in the k-Tournament Selection, and this exploration could be performed for both
pacman and the ghosts and their interactions, but after considering the scope of this project, the aforementioned configuration
comparisons were chosen instead.


\section{Results}
List your experimental results in both tabular and graphical formats (box plots preferred)
along with your statistical results, corresponding to the three configuration and log files, and six
solution files, referenced above (so you’ll have three plots and a table containing your statistical
comparison of the three combinations).

Three configurations of the EA were run to generate experimental results. These configurations, as introduced in the 
\textbf{Experimental Setup} section, were Deliverable 1: Over-Selection Parent 
Selection and k-Tournament Survival Selection (Figure \ref{fig:deliverable1}), Deliverable 2: Fitness Proportional 
Parent Selection and k-Tournament Survival Selection (Figure \ref{fig:deliverable2}), and Deliverable 3: Over-Selection Parent Selection 
and Truncation Survival Selection (Figure \ref{fig:deliverable3}). Pairwise statistical comparisons were performed as follows:
Deliverable 1 and Deliverable 2 (Table \ref{d1_d2}), Deliverable 2 and Deliverable 3 (Table \ref{d2_d3}), and Deliverable 1 and Deliverable
3 (Table \ref{d1_d3}).

The statistical analysis performed in these comparisons was done so on the final local best across thirty runs. The analysis consisted 
of first an f-test which was used to determine the assumption of equal or unequal variances. Then, a t-test (either assuming equal or unequal
variances based on the results of the f-test) was performed. This final test produced the result that either one configuration was
statistically better than the other for the given problem space or that neither algorithm configuration was statistically better 
for the given problem space.

Comparing Deliverable 1 with Deliverable 2, the statistical analysis (Table \ref{d1_d2}) showed that neither algorithm 
configuration is statistically better. Both configurations showed reasonably high variance, signaling that the stochastic algorithm's
performance in both cases was fairly unpredictable. This result also shows that, all else held constant, switching between Over-Selection
for parent selection and FPS does not produce tangible differences in performance. Both methods use a reasonably high selective pressure,
but Over-Selection was created for very large GP tree populations. In the scope of this experiment, it is possible that the limited size
of the GP populations rendered the Over-Selection method to be less effective in optimally choosing parents.

Table \ref{d2_d3} and Table \ref{d1_d3} each compare Deliverable 3 with Deliverable 1 and Deliverable 2 respectively. In both cases, the
algorithm configured with Deliverable 3 was proven to be statistically better for the given problem space. Interestingly, the high variance of
Deliverable 3 may have helped prove it as a more optimal configuration. While more sub-optimal solutions were found with Deliverable 3,
there were also many exceedingly optimal solutions found. 


\begin{figure}[H]
    \addgraphic{deliverable1}
    \fitnessplotcaption{Over-Selection Parent Selection and k-Tournament Survival Selection (Deliverable 1)}{deliverable1.cfg}
    \label{fig:deliverable1}
\end{figure}

\begin{figure}[H]
    \addgraphic{deliverable2}
    \fitnessplotcaption{Fitness Proportional Parent Selection and k-Tournament Survival Selection (Deliverable 2)}{deliverable2.cfg}
    \label{fig:deliverable2}
\end{figure}

\begin{figure}[H]
    \addgraphic{deliverable3}
    \fitnessplotcaption{Over-Selection Parent Selection and Truncation Survival Selection (Deliverable 3)}{deliverable3.cfg}
    \label{fig:deliverable3}
\end{figure}

\begin{table}[H] 
\tablecaption{Deliverable 1 and Deliverable 2}        
\label{d1_d2}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & deliverable1 & deliverable2  \\ \hline 
 mean & 107.4 & 108.13333333333334 \\ \hline 
 variance & 395.5733333333333 & 301.58222222222224 \\ \hline 
 standard deviation & 19.88902544956221 & 17.366122832175932 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 1.3116599858523932 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Equal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 58 &  \\ \hline 
  t Stat & -0.14956692976611996 &  \\ \hline 
  P two-tail & 0.8816251806191939 &  \\ \hline 
  t Critical two-tail & 2.0017 &  \\ \hline 
  Nether deliverable2 nor & & \\
 deliverable1 is statistically better &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{Deliverable 2 and Deliverable 3}        
\label{d2_d3}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & deliverable2 & deliverable3  \\ \hline 
 mean & 108.13333333333334 & 124.56666666666666 \\ \hline 
 variance & 301.58222222222224 & 578.5788888888889 \\ \hline 
 standard deviation & 17.366122832175932 & 24.05366684912903 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 0.5212465024456475 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Unequal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 31 &  \\ \hline 
  t Stat & -2.9829335278061286 &  \\ \hline 
  P two-tail & 0.004315231188237327 &  \\ \hline 
  t Critical two-tail & 2.0395 &  \\ \hline 
  deliverable3 is statistically better than deliverable2 &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{Deliverable 1 and Deliverable 3}        
\label{d1_d3}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & deliverable1 & deliverable3  \\ \hline 
 mean & 107.4 & 124.56666666666666 \\ \hline 
 variance & 395.5733333333333 & 578.5788888888889 \\ \hline 
 standard deviation & 19.88902544956221 & 24.05366684912903 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 0.6836981800234675 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Equal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 58 &  \\ \hline 
  t Stat & -2.961907970931727 &  \\ \hline 
  P two-tail & 0.004425906472211853 &  \\ \hline 
  t Critical two-tail & 2.0017 &  \\ \hline 
  deliverable3 is statistically better than deliverable1 &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\section{Discussion}
Discuss your experimental and statistical results, providing valuable insights such as conjectures
you induce from your results. Your choice of what to report on and how you go about
rationalizing it is your subjective interpretation.

\section{BONUS1}
TODO

\begin{figure}[H]
    \addgraphic{BONUS1}
    \fitnessplotcaption{BONUS1: Single pacman, multiple ghosts employing different controllers}{BONUS1.cfg}
    \label{fig:BONUS1}
\end{figure}

\begin{table}[H] 
\tablecaption{BONUS1 and Deliverable 1}        
\label{b1_d1}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS1 & deliverable1  \\ \hline 
 mean & 111.4 & 107.4 \\ \hline 
 variance & 862.0400000000001 & 395.5733333333333 \\ \hline 
 standard deviation & 29.360517706607286 & 19.88902544956221 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 2.179216664419577 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Unequal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 31 &  \\ \hline 
  t Stat & 0.6074148757553575 &  \\ \hline 
  P two-tail & 0.5462715238455983 &  \\ \hline 
  t Critical two-tail & 2.0395 &  \\ \hline 
  Nether deliverable1 nor & & \\
 BONUS1 is statistically better &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\section{BONUS2a, BONUS2b, BONUS2c, and BONUS2d}
TODO

\begin{figure}[H]
    \addgraphic{BONUS2a}
    \fitnessplotcaption{BONUS2a: Multiple pacmen employing the same controller, multiple ghosts employing the same controller}{BONUS2a.cfg}
    \label{fig:BONUS2a}
\end{figure}

\begin{figure}[H]
    \addgraphic{BONUS2b}
    \fitnessplotcaption{BONUS2b: Multiple pacmen employing different controllers, multiple ghosts employing the same controller}{BONUS2b.cfg}
    \label{fig:BONUS2b}
\end{figure}

\begin{figure}[H]
    \addgraphic{BONUS2c}
    \fitnessplotcaption{BONUS2c: Multiple pacmen employing the same controller, multiple ghosts employing different controllers}{BONUS2c.cfg}
    \label{fig:BONUS2c}
\end{figure}

\begin{figure}[H]
    \addgraphic{BONUS2d}
    \fitnessplotcaption{BONUS2d: Multiple pacmen employing different controllers, multiple ghosts employing different controllers}{BONUS2d.cfg}
    \label{fig:BONUS2d}
\end{figure}

\begin{table}[H] 
\tablecaption{BONUS2a and BONUS2b}        
\label{b2a_b2b}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS2a & BONUS2b  \\ \hline 
 mean & 140.7 & 127.6 \\ \hline 
 variance & 342.47666666666663 & 784.9733333333332 \\ \hline 
 standard deviation & 18.506125112153182 & 28.017375561128727 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 0.4362908294124641 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Equal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 58 &  \\ \hline 
  t Stat & 2.1009786982574874 &  \\ \hline 
  P two-tail & 0.03999926723492717 &  \\ \hline 
  t Critical two-tail & 2.0017 &  \\ \hline 
  BONUS2a is statistically better than BONUS2b &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{BONUS2a and BONUS2c}        
\label{b2a_b2c}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS2a & BONUS2c  \\ \hline 
 mean & 140.7 & 135.9 \\ \hline 
 variance & 342.47666666666663 & 478.02333333333337 \\ \hline 
 standard deviation & 18.506125112153182 & 21.8637447234762 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 0.7164434093175367 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Unequal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 31 &  \\ \hline 
  t Stat & 0.9024038585626759 &  \\ \hline 
  P two-tail & 0.3706762522069167 &  \\ \hline 
  t Critical two-tail & 2.0395 &  \\ \hline 
  Nether BONUS2c nor & & \\
 BONUS2a is statistically better &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{BONUS2a and BONUS2d}        
\label{b2a_b2d}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS2a & BONUS2d  \\ \hline 
 mean & 140.7 & 119.36666666666666 \\ \hline 
 variance & 342.47666666666663 & 354.3655555555555 \\ \hline 
 standard deviation & 18.506125112153182 & 18.82459974489645 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 0.9664502130568247 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Unequal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 31 &  \\ \hline 
  t Stat & 4.352016063471005 &  \\ \hline 
  P two-tail & 5.5455771508607214e-05 &  \\ \hline 
  t Critical two-tail & 2.0395 &  \\ \hline 
  BONUS2a is statistically better than BONUS2d &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{BONUS2b and BONUS2c}        
\label{b2b_b2c}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS2b & BONUS2c  \\ \hline 
 mean & 127.6 & 135.9 \\ \hline 
 variance & 784.9733333333332 & 478.02333333333337 \\ \hline 
 standard deviation & 28.017375561128727 & 21.8637447234762 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 1.6421234667763773 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Equal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 58 &  \\ \hline 
  t Stat & -1.2576968962023538 &  \\ \hline 
  P two-tail & 0.2135417162246614 &  \\ \hline 
  t Critical two-tail & 2.0017 &  \\ \hline 
  Nether BONUS2c nor & & \\
 BONUS2b is statistically better &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{BONUS2b and BONUS2d}        
\label{b2b_b2d}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS2b & BONUS2d  \\ \hline 
 mean & 127.6 & 119.36666666666666 \\ \hline 
 variance & 784.9733333333332 & 354.3655555555555 \\ \hline 
 standard deviation & 28.017375561128727 & 18.82459974489645 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 2.2151513346230667 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Unequal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 31 &  \\ \hline 
  t Stat & 1.313554924158955 &  \\ \hline 
  P two-tail & 0.1949035354931222 &  \\ \hline 
  t Critical two-tail & 2.0395 &  \\ \hline 
  Nether BONUS2d nor & & \\
 BONUS2b is statistically better &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\begin{table}[H] 
\tablecaption{BONUS2c and BONUS2d}        
\label{b2c_b2d}                 
\resizebox{\textwidth}{!}{%        
\begin{tabular}{|l|l|l|}           
\hline               
  & BONUS2c & BONUS2d  \\ \hline 
 mean & 135.9 & 119.36666666666666 \\ \hline 
 variance & 478.02333333333337 & 354.3655555555555 \\ \hline 
 standard deviation & 21.8637447234762 & 18.82459974489645 \\ \hline 
 observations & 30 & 30 \\ \hline 
 df & 29 & 29 \\ \hline 
 F & 1.348955410138307 &   \\ \hline 
 F critical & 0.5373999648406917 &   \\ \hline 
 Unequal variances assumed &  &    \\ \hline 
  &  &     \\ \hline 
  observations & 30 &  \\ \hline 
  df & 31 &  \\ \hline 
  t Stat & 3.086002570767297 &  \\ \hline 
  P two-tail & 0.0031343644838580814 &  \\ \hline 
  t Critical two-tail & 2.0395 &  \\ \hline 
  BONUS2c is statistically better than BONUS2d &  &   \\ \hline 
  \end{tabular}%     
}                    
\end{table}

\section{Conclusion}
Conclude your report by stating your most important findings and insights in the conclusion
section.

\section{Bibliography}
This is where you provide your citation details, if you cited anything. Only list references
here that you actually cite in your report.

\section{Appendices}
If you have more data you want to show than what you could reasonably fit in the body
of your report, this is the place to put it along with a short description.

\end{document}
